{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rSb_IY4zkIbm",
        "aSnyLTvgkYOl",
        "vjoI0rlkkeOZ",
        "W-zwj5HfmUs6",
        "TVFD4h3V51K1",
        "aJbbHB8gXZuQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## AND"
      ],
      "metadata": {
        "id": "aQpWavO_P_Uq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGL6LztrOgf4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from random import random,randint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Алгоритм обучения персептрона. Первый способ (через функции)"
      ],
      "metadata": {
        "id": "rSb_IY4zkIbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1 = random()\n",
        "w2 = random()\n",
        "bias = randint(-10,-2)   # W подбирается только при этих значениях смещения (не знаю почему так) - вероятно тут ошибка, хотя ответ верный\n",
        "\n",
        "X1 = [0,0,1,1]\n",
        "X2 = [0,1,0,1]\n",
        "\n",
        "y_target = [0,0,0,1]\n",
        "\n",
        "y_predict = []\n",
        "\n",
        "def calculate_sum(x1,x2,w1,w2,delta):\n",
        "  return (x1*w1 + x2*w2 + delta)\n",
        "\n",
        "\n",
        "def activation_func(operation_result):\n",
        "  if operation_result > 0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def prediction(input1,input2,w1,w2, calc_sum, activation):\n",
        "  y_pred = []\n",
        "  for i in range(len(input1)):\n",
        "    sum = calc_sum(input1[i],input2[i],w1,w2,bias)\n",
        "    y_pred.append(activation(sum))\n",
        "  return y_pred\n",
        "\n",
        "def w_config(input1, input2, y_pred, y_true, w1, w2, delta, pred_operation,calc_sum,activation):\n",
        "  perfect = False\n",
        "  while not perfect:\n",
        "    perfect = True\n",
        "    y_pred = pred_operation(input1,input2,w1,w2,calc_sum,activation)\n",
        "    for i in range(len(input1)):\n",
        "      if y_pred[i] != y_true[i]:\n",
        "        perfect = False\n",
        "        if y_pred[i] == 0:\n",
        "          w1 += input1[i]\n",
        "          w2 += input2[i]\n",
        "          delta += 1\n",
        "        else:\n",
        "          w1 -= input1[i]\n",
        "          w2 -= input2[i]\n",
        "          delta -=1     \n",
        "  return (w1,w2,delta)"
      ],
      "metadata": {
        "id": "Jr-Z013PE_gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w1,w2,bias)"
      ],
      "metadata": {
        "id": "WCNfj6NXpHEW",
        "outputId": "b419f6bc-1d8d-41db-bc5a-988b007c8314",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6717534038418486 0.6674672194115314 -2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = prediction(X1,X2,w1,w2, calculate_sum,activation_func)\n",
        "y_predict"
      ],
      "metadata": {
        "id": "Sr9AGnzUcSiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93faebb-5150-437e-fe19-1c6cbf51debe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = w_config(X1,X2, y_predict, y_target, w1, w2,bias,prediction,calculate_sum,activation_func)\n",
        "W"
      ],
      "metadata": {
        "id": "vLbl2peDnK-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf94aef-d946-40b7-dbed-0109464fe615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.6717534038418487, 1.6674672194115314, -1)"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predict = prediction(X1,X2,W[0],W[1], calculate_sum,activation_func)\n",
        "y_predict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ufKyIHXDQRI",
        "outputId": "2c5b811d-bbe6-4f04-a4ce-68a392de7938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Алгоритм обучения персептрона. Второй способ (ООП)"
      ],
      "metadata": {
        "id": "aSnyLTvgkYOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "  def __init__(self):\n",
        "    self.w1 = random()\n",
        "    self.w2 = random()\n",
        "\n",
        "    self.bias = randint(-10,-2)    # W подбирается только при этих значениях смещения (не знаю почему так) - вероятно тут ошибка, хотя ответ верный\n",
        "\n",
        "    self.y_predict = []\n",
        "\n",
        "  def calculate_sum(self,x1,x2,w1,w2,delta):\n",
        "    return (x1*w1 + x2*w2 + delta)\n",
        "  \n",
        "\n",
        "  def activation_func(self, calculate_sum):\n",
        "    if calculate_sum > 0:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "  def prediction(self, X1_input,X2_input):\n",
        "    y_pred = []\n",
        "    for i in range(len(X1_input)):\n",
        "      sum = self.calculate_sum(X1_input[i],X2_input[i],self.w1,self.w2,self.bias)\n",
        "      y_pred.append(self.activation_func(sum))\n",
        "    return y_pred\n",
        "\n",
        "  def w_config(self,X1_input,X2_input,y_true,learning_rate = 1):\n",
        "    lr = learning_rate\n",
        "    perfect = False\n",
        "    while not perfect:\n",
        "      perfect = True\n",
        "      self.y_predict = self.prediction(X1_input,X2_input)\n",
        "      for i in range(len(X1_input)):\n",
        "        if self.y_predict[i] != y_true[i]:\n",
        "          perfect = False\n",
        "          if self.y_predict[i] == 0:\n",
        "            self.w1 += lr*X1_input[i]\n",
        "            self.w2 += lr*X2_input[i]\n",
        "            self.bias += lr*1\n",
        "          else:\n",
        "            self.w1 -= lr*X1_input[i]\n",
        "            self.w2 -= lr*X2_input[i]\n",
        "            self.bias -= lr*1     \n",
        "    return (self.w1,self.w2,self.bias)\n",
        "  "
      ],
      "metadata": {
        "id": "lJfgIdt7h6_y"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = [0,0,1,1]\n",
        "X2 = [0,1,0,1]\n",
        "\n",
        "y_target = [0,0,0,1]"
      ],
      "metadata": {
        "id": "1uG-bafbMGRX"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A = Neuron()"
      ],
      "metadata": {
        "id": "DFfOoUJjm1TD"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W = A.w_config(X1,X2,y_target)\n",
        "W"
      ],
      "metadata": {
        "id": "UdXMi711uJhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5c5f56-6f46-4ee4-a1c3-6810c622cfc7"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.121495530384081, 3.8333755057274344, -6)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.prediction(X1,X2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wM1cOGhYjt69",
        "outputId": "8b537f3b-d473-4fd2-b6e9-bd13a97ef2ff"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Алгоритм обучения персептрона. Третий способ (ООП + Numpy)"
      ],
      "metadata": {
        "id": "vjoI0rlkkeOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "  def __init__(self):\n",
        "    self.W = np.random.rand(3,1)\n",
        "\n",
        "\n",
        "  def calculate_sum(self,X_input):\n",
        "    return np.dot(X_input,self.W)\n",
        "  \n",
        "\n",
        "  def activation_func(self,X_input):\n",
        "    a = self.calculate_sum(X_input)\n",
        "    return np.where(a > 0, 1,0)\n",
        "\n",
        "  def w_config(self,X_input,y_input, learning_rate = 1):\n",
        "    lr = learning_rate\n",
        "    perfect = False\n",
        "    while not perfect:\n",
        "      perfect = True\n",
        "      y_predict = self.activation_func(X_input)\n",
        "      for i in range(len(X_input)):\n",
        "        if y_predict[i] != y_input[i]:\n",
        "          perfect = False\n",
        "          if y_predict[i] == 0:\n",
        "            self.W += lr*X_input[i].reshape(3,1)\n",
        "          else:\n",
        "            self.W -= lr*X_input[i].reshape(3,1)   \n",
        "    return (self.W)"
      ],
      "metadata": {
        "id": "V3FfSZcGIa91"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0,0,1],       # Убрать из класса (подаём из вне)\n",
        "              [0,1,1],\n",
        "              [1,0,1],\n",
        "              [1,1,1]])\n",
        "    \n",
        "y_target = np.array([[0],    # Убрать из класса (подаём из вне)\n",
        "                     [0],\n",
        "                     [0], \n",
        "                     [1]])"
      ],
      "metadata": {
        "id": "OzHGTQ3VOY9g"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Perceptron()"
      ],
      "metadata": {
        "id": "3_HdS6OtKPED"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.w_config(X,y_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlHvkDROiVHT",
        "outputId": "c43c2e36-beab-46fa-c982-6b86110aec2f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.16059902],\n",
              "       [ 1.20514605],\n",
              "       [-2.03977066]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.activation_func(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15abKI0yk6x2",
        "outputId": "8125dc80-67f5-4c32-dd20-7abfe87b6e93"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Через градиентный спуск"
      ],
      "metadata": {
        "id": "W-zwj5HfmUs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron_gradient:\n",
        "  def __init__(self):\n",
        "    self.W = np.random.rand(3,1)\n",
        "\n",
        "\n",
        "  def calculate_sum(self,X_input):\n",
        "    return np.dot(X_input,self.W)\n",
        "  \n",
        "\n",
        "  def activation_func(self,X_input):\n",
        "    a = self.calculate_sum(X_input)\n",
        "    return np.where(a > 0, 1,0)\n",
        "\n",
        "\n",
        "  def w_config(self,X_input,y_input, learning_rate = 0.3):\n",
        "    lr = learning_rate\n",
        "    perfect = False\n",
        "    while not perfect:\n",
        "      perfect = True\n",
        "      y_predict = self.activation_func(X_input)\n",
        "      for i in range(len(X_input)):\n",
        "        if y_predict[i] != y_input[i]:\n",
        "          error = y_input[i] - y_predict[i]\n",
        "          perfect = False\n",
        "          self.W -= -lr*2*error*1*X_input[i].reshape(3,1)       \n",
        "    return (self.W)"
      ],
      "metadata": {
        "id": "z0MUkSAVMy4Q"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0,0,1],         # Убрать из класса (подаём из вне)\n",
        "              [0,1,1],\n",
        "              [1,0,1],\n",
        "              [1,1,1]])\n",
        "    \n",
        "y_target = np.array([[0],      # Убрать из класса (подаём из вне)\n",
        "                     [0],\n",
        "                     [0], \n",
        "                     [1]])"
      ],
      "metadata": {
        "id": "hdGZQYYxQL9-"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Perceptron_gradient()"
      ],
      "metadata": {
        "id": "vYSrIZYI4gJv"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.w_config(X,y_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s4IX7bk4jw8",
        "outputId": "71d7e583-a017-4f9e-fd1f-f1d89191a27f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.06238422],\n",
              "       [ 0.85493299],\n",
              "       [-1.34876299]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.activation_func(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM8zDBYW4s9m",
        "outputId": "e3bbb7f6-038e-4256-81a5-e490cae60636"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OR"
      ],
      "metadata": {
        "id": "TVFD4h3V51K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "  def __init__(self):\n",
        "    self.W = np.random.rand(3,1)\n",
        "\n",
        "\n",
        "  def calculate_sum(self,X_input):\n",
        "    return np.dot(X_input,self.W)\n",
        "  \n",
        "\n",
        "  def activation_func(self,X_input):\n",
        "    a = self.calculate_sum(X_input)\n",
        "    return np.where(a > 0, 1,0)\n",
        "\n",
        "  def w_config(self,X_input,y_input, learning_rate = 1):\n",
        "    lr = learning_rate\n",
        "    perfect = False\n",
        "    while not perfect:\n",
        "      perfect = True\n",
        "      y_predict = self.activation_func(X_input)\n",
        "      for i in range(len(X_input)):\n",
        "        if y_predict[i] != y_input[i]:\n",
        "          perfect = False\n",
        "          if y_predict[i] == 0:\n",
        "            self.W += lr*X_input[i].reshape(3,1)\n",
        "          else:\n",
        "            self.W -= lr*X_input[i].reshape(3,1)   \n",
        "    return (self.W)"
      ],
      "metadata": {
        "id": "Dq1R-uQa55X9"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0,0,1],       # Убрать из класса (подаём из вне)\n",
        "              [0,1,1],\n",
        "              [1,0,1],\n",
        "              [1,1,1]])\n",
        "    \n",
        "y_target = np.array([[0],    # Убрать из класса (подаём из вне)\n",
        "                     [1],\n",
        "                     [1], \n",
        "                     [1]])"
      ],
      "metadata": {
        "id": "HUH9hTr6RC2Y"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = Perceptron_gradient()"
      ],
      "metadata": {
        "id": "Cdjhezh06zjN"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.w_config(X,y_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YCKuMNx622u",
        "outputId": "ab9d2e38-28ab-454b-f997-d13d3ba18907"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.82238347],\n",
              "       [ 0.71672302],\n",
              "       [-0.3583208 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.activation_func(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHwRJ8l367pN",
        "outputId": "28bc94f5-8457-404b-870d-02c236dbe0fc"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1]])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Распознавание цифр"
      ],
      "metadata": {
        "id": "aJbbHB8gXZuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt \n",
        "import math\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "GSqOxTMiXjDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = np.array(X_train, dtype = 'float64')\n",
        "y_train = y_train\n",
        "\n",
        "X_test = np.array(X_test, dtype = 'float64')\n",
        "y_test = y_test\n",
        "\n",
        "\n",
        "##### Нормализация данных. Приведем значение пикселей в диапазон от 0 до 1\n",
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "gFdyUNZuXrmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.imshow(X_train[0])\n",
        "plt.colorbar()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "rbcBXRWYssqE",
        "outputId": "69e85f29-2948-4925-f04e-30e83ebd2733"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f857edcb130>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAD8CAYAAADJwUnTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWwklEQVR4nO3df5AdVZnG8e/jEJIlRCVGY4QoEcNqRA06C1hQgoVioCyRUpHoKioaF42KoiuyFiCrVegqLmKW3UEjYMlvUbNuNCqroi7EDIiQgGCMQRJDYggggpDkzrt/dEfu/Ljn9szcme6ePJ+qrrndb/fpYwOvfU6fPq2IwMysTp5UdgXMzIbLicvMaseJy8xqx4nLzGrHicvMaseJy8xqx4nLzMaMpKWStkha3SIuSV+StFbSbZJeWqRcJy4zG0uXAAsS8WOBufmyCLioSKFOXGY2ZiLiBmBbYpfjgcsicxPwVEmz2pW7R6cqWMSemhxTmDqepzTbrTzGI2yPxzWaMl7zyqlx/7ZGoX1vvu3xNcBjTZt6IqJnGKfbF7i3aX1Dvm1T6qBRJS5JC4ALgC7gKxFxXmr/KUzlUB09mlOaWcLKuH7UZdy/rcEvVzy70L5ds377WER0j/qkwzTixCWpC1gCvJosS66StCwi7uhU5cxs/AXQR994nW4jMLtpfb98W9Jo+rgOAdZGxLqI2A5cSdZeNbMaC4Id0Si0dMAy4O3508XDgIciItlMhNE1FYdqmx46cCdJi8ieFjCFvUZxOjMbL52645J0BXAUMEPSBuBsYBJARPwnsBw4DlgLPAq8s0i5Y945n3fU9QA8WdM9h45ZxQVBo0PTXUXEwjbxAN4/3HJHk7hG1DY1s+rro9r3GKNJXKuAuZLmkCWsk4C3dKRWZlaaABoTNXFFxE5Ji4EVZMMhlkbEmo7VzMxKM5HvuIiI5WSda2Y2QQSwo+JTuo/ryHkzq74gJm5T0cwmqIBGtfOWE5eZ9ZeNnK82Jy4zG0A0GNV72mPOicvM+sk65524zKxGsnFcTlxmVjN9vuMyszrxHZeZ1U4gGhWf1d2Jy8wGcVPRzGolENujq+xqJDlxmVk/2QBUNxXNrGbcOW9mtRIhGuE7LjOrmT7fcZlZnWSd89VODdWunZmNO3fOm1ktNTyOy8zqxCPnzayW+vxU0czqJHvJ2onLzGokEDv8yo+Z1UkEHoBqZnUjD0A1s3oJfMdlZjXkznkzq5VAnkjQzOol+zxZtVNDtWtnZiXwB2GtZNoj/Y+46+kzxvT8d310/5axxl7pD70/54Atyfhe70v/x3Xf+Xu2jN3SfVXy2K2NR5LxQ685PRl/3kduSsarLJjgI+clrQceBhrAzojo7kSlzKxcVb/j6kRafWVEzHfSMpsYIkRfPKnQUoSkBZLukrRW0hlDxJ8t6ceSfiXpNknHtSvTTUUz6yfrnO/MKz+SuoAlwKuBDcAqScsi4o6m3T4JXB0RF0maBywH9k+VO9o7rgB+IOlmSYtaVHyRpF5JvTt4fJSnM7Oxl805X2Qp4BBgbUSsi4jtwJXA8QP2CeDJ+e+nAH9sV+ho77iOiIiNkp4B/FDSbyLihn41iugBegCerOkxyvOZ2RjLOucL93HNkNTbtN6T/ze/y77AvU3rG4BDB5RxDtkN0AeAqcCr2p10VIkrIjbmf7dI+hZZdr0hfZSZVd0wRs5v7UD/9kLgkoj4gqSXA1+XdFBEtHzsPOKmoqSpkqbt+g0cA6weaXlmVg27Rs4XWQrYCMxuWt8v39bsFOBqgIi4EZgCJMfpjOaOaybwLUm7yrk8Ir4/ivImrK4XzE3GY/KkZPyPRz41Gf/rYa3HHE1/Sno80s9ekh7PVKbvPTotGf/slxck4ytfdHnL2O93/DV57HmbX52MP+tnE7vXo4Mfy1gFzJU0hyxhnQS8ZcA+fwCOBi6R9AKyxPWnVKEjTlwRsQ54yUiPN7NqioAdfZ1JXBGxU9JiYAXQBSyNiDWSzgV6I2IZcDpwsaQPk3WxvSMikv/P4OEQZtZP1lTs3Mj5iFhONsShedtZTb/vAA4fTplOXGY2SNVHzjtxmVk/wxwOUQonLjMboLNNxbHgxGVmg3jO+d1A46iXJuPnX7IkGT9wUuvpVyayHdFIxs+68B3J+B6PpIckvPyaxS1j0zbuTB47eWt6uMRevSuT8TrLnir682RmViOeutnMaslNRTOrFT9VNLNa8lNFM6uVCLHTicvM6sZNRTOrFfdx7SYm35Weafbmx2Yn4wdO2tzJ6nTU6ZsOS8bX/SX9ebNLDri2ZeyhvvQ4rJlf+r9kfCxN7Elr2nPiMrNa8TguM6slj+Mys1qJgJ0dmkhwrDhxmdkgbiqaWa24j8vMaimcuMysbtw5vxvYuem+ZPzCz74pGf/MgvQnxLpu2zsZ//X7LkzGUz699cXJ+NpX7ZWMNx7clIy/5eXvaxlb/8Hkoczh1+kdbExEuI/LzGpHNPxU0czqxn1cZlYrflfRzOonsn6uKnPiMrNB/FTRzGol3DlvZnXkpqIx/Ws3JuNP/++nJeON+7cl4y886F0tY2tesTR57LKeI5PxZzw4ujmxdGPrsVhz0pfFSlT1p4pt7wclLZW0RdLqpm3TJf1Q0m/zv/uMbTXNbLxEZImryFKWIg3ZS4AFA7adAVwfEXOB6/N1M5sg+kKFlrK0TVwRcQMwsK1yPHBp/vtS4PUdrpeZlSii2FKWkfZxzYyIXS+p3QfMbLWjpEXAIoAppN97M7PyBaKv4k8VR127iAgS3xaIiJ6I6I6I7klMHu3pzGwcRMGlLCNNXJslzQLI/27pXJXMrFQd7pyXtEDSXZLWShqyP1zSiZLukLRG0uXtyhxp4loGnJz/Phn4zgjLMbMq6tAtl6QuYAlwLDAPWChp3oB95gKfAA6PiBcCp7Urt20fl6QrgKOAGZI2AGcD5wFXSzoFuAc4sf3/BGulsfX+UR2/4897jvjYF771jmT8Txd1pQvoa4z43FZdHRzqcAiwNiLWAUi6kuzhXvO/eO8BlkTEA9m5o20Lrm3iioiFLUJHtzvWzOongL6+wolrhqTepvWeiOhpWt8XuLdpfQNw6IAyDgSQ9AugCzgnIr6fOqlHzptZfwEUv+PaGhHdozzjHsBcspbdfsANkl4UEQ+2OqDazzzNrBQdHMe1EZjdtL5fvq3ZBmBZROyIiN8Dd5MlspacuMxssM6Nh1gFzJU0R9KewElkD/eafZvsbgtJM8iajutShbqpaGYDdO49xIjYKWkxsIKs/2ppRKyRdC7QGxHL8tgxku4AGsDHIiL5xMqJy8wG6+Do0ohYDiwfsO2spt8BfCRfCnHimgBe8PG7W8be+aL0w9+vPef6ZPzIN70/GZ921U3JuNVQQBR/qlgKJy4zG4ITl5nVjWdANbPaceIys1oZ3gDUUjhxmdkg/liGmdWPnyqaWd3Id1w21hoPPtQydv+pL0ge+4dlf03Gz/j0Zcn4J048IRmPXz2lZWz2Z9p8n6zq7ZWJquzpTQtw4jKzAeTOeTOrId9xmVnt9JVdgTQnLjPrz+O4zKyO/FTRzOqn4onLM6CaWe34jmuC6/v1ncn4SZ/6WDL+jbM/n4zfelh6nBeHtQ69cOri5KFzL96UjO9ctz59bhsxNxXNrF4Cv/JjZjXkOy4zqxs3Fc2sfpy4zKx2nLjMrE4UbiqaWR35qaJV2fSl6TmxFt+V/q7ik8/bkIxf8dwVLWNr3v7l5LHPn/3uZPzvP5UeP934bfIr7pZQ9TuutiPnJS2VtEXS6qZt50jaKOnWfDlubKtpZuMqCi4lKfLKzyXAgiG2fzEi5ufL8iHiZlZH8UQ/V7ulLG0TV0TcAGwbh7qYWVVMgDuuVhZLui1vSu7TaidJiyT1SurdweOjOJ2ZjRf1FVvKMtLEdRFwADAf2AR8odWOEdETEd0R0T2JySM8nZnZE0aUuCJic0Q0IqIPuBg4pLPVMrNSTcSmoqRZTasnAKtb7WtmNVODzvm247gkXQEcBcyQtAE4GzhK0nyynLseeO8Y1tFKpF/cmow/+sZnJOP/8OYPtIyt/PgFyWN/88qvJONv3f+YZPyhI5JhS6n4OK62iSsiFg6x+atjUBczq4q6Jy4z272Icp8YFuE5582svw73cUlaIOkuSWslnZHY7w2SQlJ3uzKduMxssA49VZTUBSwBjgXmAQslzRtiv2nAh4CVRarnxGVmg3VuOMQhwNqIWBcR24ErgeOH2O9fgc8CjxUp1InLzAYZRlNxxq43Y/Jl0YCi9gXubVrfkG974lzSS4HZEfE/RevnznkblcbmLcn4zC+1jj/2zzuTx+6lPZPxi/f/bjL+2hNOa132twq1SHZfxZ8qbo2Itn1SrUh6EnA+8I7hHOfEZWb9RUefKm4EZjet75dv22UacBDwE0kAzwSWSXpdRPS2KtSJy8wG69w4rlXAXElzyBLWScBb/naaiIeAGbvWJf0E+GgqaYH7uMxsCJ0aDhERO4HFwArgTuDqiFgj6VxJrxtp/XzHZWaDdXDkfD7R6PIB285qse9RRcp04jKz/kqe+aEIJy4z60dU/2MZTlxmNogTl9Va3xHzk/HfvWlKMn7Q/PUtY+3GabVz4baDk/G9vpN8MGUpTlxmVjtOXGZWKyXPblqEE5eZDebEZWZ1U/WJBJ24zGwQNxXNrF48ANXMasmJy8qk7oOS8bs/2GbOq8MvTcZfMWX7sOtU1OOxIxm/aducdAF9mzpYm92HR86bWS2pr9qZy4nLzPpzH5eZ1ZGbimZWP05cZlY3vuMys/px4jKzWunsV37GRNvEJWk2cBkwkywP90TEBZKmA1cB+wPrgRMj4oGxq+rua485z0nGf/fOZ7WMnfPmK5PHvmHvrSOqUyecuTn9Ob6fXnBYMr7PpTd2sjqWq8M4riJf+dkJnB4R84DDgPdLmgecAVwfEXOB6/N1M5sIIootJWmbuCJiU0Tckv9+mOwTQ/sCxwO7hlVfCrx+rCppZuOrU58nGyvD6uOStD9wMLASmBkRu96puI+sKWlmdTeRBqBK2hv4JnBaRPw5/1w2ABER0tD5V9IiYBHAFPYaXW3NbFxUvXO+0JesJU0iS1rfiIjr8s2bJc3K47OALUMdGxE9EdEdEd2TmNyJOpvZGFNfsaUsbROXslurrwJ3RsT5TaFlwMn575OB73S+emY27oLKd84XaSoeDrwNuF3Srfm2M4HzgKslnQLcA5w4NlWsvz32f3Yy/tDLZiXjbz73+8n4Pz31umR8LJ2+KT1k4cb/aD3kYfolv0weu0+fhzuUperDIdomroj4OdnQjqEc3dnqmFkl1D1xmdnupQ4DUJ24zKy/CE8kaGY1VO285cRlZoO5qWhm9RKAm4pmVjvVzltOXEXtMeuZLWPblk5NHnvqnJ8m4wunbR5RnTph8cYjkvFbLpqfjM+4dnUyPv1hj8Wqo042FSUtAC4AuoCvRMR5A+IfAd5NNhPNn4B3RcQ9qTILvfJjZrsX9UWhpW05UhewBDgWmAcszKfFavYroDsiXgxcC3yuXblOXGbWXwxjae8QYG1ErIuI7cCVZFNiPXG6iB9HxKP56k3Afu0KdVPRzPrJBqAWbivOkNTbtN4TET1N6/sC9zatbwAOTZR3CvC9did14jKzwYrP/LA1ItJzcBck6R+BbuDIdvs6cZnZIMO442pnIzC7aX2/fFv/80mvAv4FODIiHm9XqPu4zKy/zvZxrQLmSpojaU/gJLIpsf5G0sHAfwGvi4gh5/UbyHdcZjZA595VjIidkhYDK8iGQyyNiDWSzgV6I2IZ8G/A3sA1+czKf4iI16XK3W0S1/bXpJvh2z+8LRk/83nLW8aO+btHRlSnTtnc+GvL2CuWnZ489vmf/E0yPv3B9Disis/wayPVwUkCI2I5sHzAtrOafr9quGXuNonLzAqaCB+ENbPdUInTMhfhxGVmg1U7bzlxmdlg6qt2W9GJy8z6Cyr/1MWJy8z6EdHJAahjwonLzAZz4qqG9a9PvyRw94uuGbNzL3nwgGT8gp8ek4yr0errcJnnf/r3LWNzN69MHttIRm235cRlZrXiPi4zqyM/VTSzmgk3Fc2sZgInLjOroWq3FJ24zGwwj+Mys/qpe+KSNBu4DJhJ1vrtiYgLJJ0DvIfsO2gAZ+bz7lTSgaf+Mhl/7akvG6eaDHYg6bq147FY1lER0Kh2W7HIHddO4PSIuEXSNOBmST/MY1+MiM+PXfXMrBR1v+OKiE3Apvz3w5LuJPvkkJlNVBVPXMP6WIak/YGDgV3vkSyWdJukpZL2aXHMIkm9knp30PbjHWZWtgD6othSksKJS9LewDeB0yLiz8BFwAHAfLI7si8MdVxE9EREd0R0T2JyB6psZmMrIPqKLSUp9FRR0iSypPWNiLgOICI2N8UvBr47JjU0s/EVVL5zvu0dl7LvBX0VuDMizm/aPqtptxOA1Z2vnpmVIqLYUpIid1yHA28Dbpd0a77tTGChpPlk+Xk98N4xqaGZjb+Kd84Xear4c2CoCaEqO2bLzEbDL1mbWd0E4GltzKx2fMdlZvUyMV75MbPdSUCUOEarCCcuMxusxFHxRThxmdlg7uMys1qJ8FNFM6sh33GZWb0E0aj29JROXGbW365pbSrMicvMBqv4cIhhTSRoZhNfANEXhZYiJC2QdJektZLOGCI+WdJVeXxlPmFpkhOXmfUXnZtIUFIXsAQ4FphHNqvMvAG7nQI8EBHPA74IfLZduU5cZjZINBqFlgIOAdZGxLqI2A5cCRw/YJ/jgUvz39cCR+fzALY0rn1cD/PA1h/Ftfc0bZoBbB3POgxDVetW1XqB6zZSnazbc0ZbwMM8sOJHce2MgrtPkdTbtN4TET1N6/sC9zatbwAOHVDG3/aJiJ2SHgKeRuKajGviioinN69L6o2I7vGsQ1FVrVtV6wWu20hVrW4RsaDsOrTjpqKZjaWNwOym9f3ybUPuI2kP4CnA/alCnbjMbCytAuZKmiNpT+AkYNmAfZYBJ+e/3wj8b0R66H7Z47h62u9SmqrWrar1AtdtpKpct1HJ+6wWAyuALmBpRKyRdC7QGxHLyD7G83VJa4FtZMktSW0Sm5lZ5bipaGa148RlZrVTSuJq9wpAmSStl3S7pFsHjE8poy5LJW2RtLpp23RJP5T02/zvPhWq2zmSNubX7lZJx5VUt9mSfizpDklrJH0o317qtUvUqxLXrU7GvY8rfwXgbuDVZIPRVgELI+KOca1IC5LWA90RUfpgRUmvAP4CXBYRB+XbPgdsi4jz8qS/T0R8vCJ1Owf4S0R8frzrM6Bus4BZEXGLpGnAzcDrgXdQ4rVL1OtEKnDd6qSMO64irwAYEBE3kD1ladb8esSlZP/ij7sWdauEiNgUEbfkvx8G7iQbnV3qtUvUy4apjMQ11CsAVfqHF8APJN0saVHZlRnCzIjYlP++D5hZZmWGsFjSbXlTspRmbLN8poGDgZVU6NoNqBdU7LpVnTvnBzsiIl5K9jb7+/MmUSXlg/SqNJ7lIuAAYD6wCfhCmZWRtDfwTeC0iPhzc6zMazdEvSp13eqgjMRV5BWA0kTExvzvFuBbZE3bKtmc95Xs6jPZUnJ9/iYiNkdEI7KP8l1MiddO0iSy5PCNiLgu31z6tRuqXlW6bnVRRuIq8gpAKSRNzTtNkTQVOAZYnT5q3DW/HnEy8J0S69LPrqSQO4GSrl0+JcpXgTsj4vymUKnXrlW9qnLd6qSUkfP5495/54lXAD4z7pUYgqTnkt1lQfY61OVl1k3SFcBRZNOebAbOBr4NXA08G7gHODEixr2TvEXdjiJr7gSwHnhvU5/SeNbtCOBnwO3ArtnuziTrTyrt2iXqtZAKXLc68Ss/ZlY77pw3s9px4jKz2nHiMrPaceIys9px4jKz2nHiMrPaceIys9r5f+JArXTTziBJAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron_gradient:\n",
        "  def __init__(self,y_target):\n",
        "    # Каждый вход нейрона - пиксель картинки\n",
        "    # Всего входов у нейрона 28x28 = 784\n",
        "    self.W = np.random.rand(785,1) / 1000                  # вектор размерностью (784 + 1) x 1  с учетом смещения\n",
        "    self.y_target = y_target                               # число, которое будем распознавать\n",
        "\n",
        "  def calculate_sum(self, X_input):                          # считаем взвешенную сумму\n",
        "    return np.dot(X_input,self.W)                            # Важно, чтобы размерности векторов были X: 1 x 784+1 (x0 = 1 - для смещения) и W: (784 + 1) x 1  с учетом смещения. Изначально размерность X: 28x28\n",
        "\n",
        "  def sigmoida(self,X_input):                               # считаем функцию активации\n",
        "    return 1 /(1 + math.exp(-self.calculate_sum(X_input)))\n",
        "\n",
        "  def sigmoid_derivative(self,X_input):                     # считаем производную функции активации\n",
        "    return self.sigmoida(X_input)*(1 - self.sigmoida(X_input))\n",
        "  \n",
        "  # считаем, что картинка распознана верно, если функция активации от её вектора > 0.5, иначе картинка распознана неправильно\n",
        "  def w_config(self, X_input, y_input, learning_rate = 0.01):    # подбираем веса \n",
        "    lr = learning_rate                                           # скорость обучения\n",
        "    # если лейбл картинки совпадает с тем числом, которое мы хотим распознать И выход функции активации меньше 0.5, то:\n",
        "    if (y_input == self.y_target) and (self.sigmoida(X_input) < 0.5):    # если лейбл картинки совпадает с тем, числом, которое мы хотим распознать, но сумма активации меньше 0.5, то:\n",
        "      activation_true = 1                                        # стремимся, чтобы функцияя активации равнялась 1                                                \n",
        "      activation_predict = self.sigmoida(X_input)                # считаем функцию активации\n",
        "      error = activation_true - activation_predict               # считаем ошибку\n",
        "      self.W -= -lr * 2 * error * self.sigmoid_derivative(X_input) * X_input.reshape(785,1)      # считаем веса\n",
        "    # если лейбл картинки НЕ совпадает с тем числом, которое мы хотим распознать И выход функции активации больше 0.5, то:\n",
        "    elif (y_input != self.y_target) and (self.sigmoida(X_input) > 0.5): \n",
        "      activation_true = 0\n",
        "      activation_predict = self.sigmoida(X_input)\n",
        "      error = activation_true - activation_predict\n",
        "      self.W -= -lr * 2 * error * self.sigmoid_derivative(X_input) * X_input.reshape(785,1)\n",
        "\n",
        "    return self.sigmoida(X_input)"
      ],
      "metadata": {
        "id": "iz8AlARU7mIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция обучения на всей выборке\n",
        "def learning(A, X_input, y_input):\n",
        "  for i in range(len(X_input)):\n",
        "    X = np.insert(X_input[i].flatten(),0,1)       # вектор размерностью 1 x 784+1 (x0 = 1 - для смещения)\n",
        "    A.w_config(X,y_input[i])"
      ],
      "metadata": {
        "id": "vv2SUpoPYuPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция подсчета ошибки\n",
        "def test_accuracy(A, y_target, X_input_test = X_test, y_input_test = y_test):\n",
        "  counter0 = 0     # считаем количество верно угаданных чисел (counter += 1, если хотели 4 и верно её угадали (функция активации > 0.5) и\n",
        "                                                                # и counter += 1, если число не равно 4, но и функция активации < 0.5)\n",
        "\n",
        "  counter1 = 0     # считаем количество верно угаданных чисел (counter += 1, если хотели 4 и верно её угадали (функция активации > 0.5))\n",
        "  counter2 = 0     # считаем общее количество лейблов желаемых чисел во всей выборке \n",
        "\n",
        "  for i in range(len(X_input_test)):\n",
        "    X = np.insert(X_input_test[i].flatten(),0,1)\n",
        "    if A.sigmoida(X) > 0.5 and y_input_test[i] == y_target:\n",
        "      counter0 +=1\n",
        "      counter1 +=1\n",
        "\n",
        "    elif A.sigmoida(X) < 0.5 and y_input_test[i] != y_target:\n",
        "      counter0 += 1\n",
        "\n",
        "    if y_input_test[i] == y_target:\n",
        "      counter2 +=1\n",
        "\n",
        "  accuracy = counter0 / len(y_input_test) * 100      # доля верно отгаданных чисел\n",
        "  accuracy_y_target = counter1 / counter2 * 100      # доля верно отгаданных четвёрок от общего количества четверок\n",
        "\n",
        "  return (accuracy, accuracy_y_target)"
      ],
      "metadata": {
        "id": "0_VDbO21aWoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучаем 9 нейронов (каждый нейрон распознает одну цифру от 0 до 9) и считаем показатели точности."
      ],
      "metadata": {
        "id": "52VuNOMoCOhA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a0 = Perceptron_gradient(0)\n",
        "learning(a0,X_train,y_train)\n",
        "test_accuracy(a0,0)"
      ],
      "metadata": {
        "id": "-vJHmSoVQ9lv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d933f30d-47c8-44e5-f1ab-4e63d4225025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98.25, 83.36734693877551)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = Perceptron_gradient(1)\n",
        "learning(a1,X_train,y_train)\n",
        "test_accuracy(a1,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmtBPFzCZQfH",
        "outputId": "59932bec-ffe8-4e51-b7b5-c060d429ec05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99.15, 97.3568281938326)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a2 = Perceptron_gradient(2)\n",
        "learning(a2,X_train,y_train)\n",
        "test_accuracy(a2,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV23fwyEcWjQ",
        "outputId": "5722ecad-61d4-4a2c-baee-466809ae74fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95.37, 55.81395348837209)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a3 = Perceptron_gradient(3)\n",
        "learning(a3,X_train,y_train)\n",
        "test_accuracy(a3,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZVhFA9Qfr1a",
        "outputId": "712bcbc2-f4b6-44ad-ac66-ed8345df9c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(96.64, 88.91089108910892)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a4 = Perceptron_gradient(4)\n",
        "learning(a4,X_train,y_train)\n",
        "test_accuracy(a4,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBdsF5Qzf2LF",
        "outputId": "2d51d7d0-c860-446f-819b-5ed13f807bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(97.17, 75.96741344195519)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a5 = Perceptron_gradient(5)\n",
        "learning(a5,X_train,y_train)\n",
        "test_accuracy(a5,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rfJ8nmgf82G",
        "outputId": "19cfc8eb-82d3-4573-c7c7-93b40d9399a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(95.03, 46.52466367713004)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a6 = Perceptron_gradient(6)\n",
        "learning(a6,X_train,y_train)\n",
        "test_accuracy(a6,6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idq3eaeOgHh9",
        "outputId": "bd0c2e02-da7a-4b63-998d-bb1bad179712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98.22, 90.91858037578288)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a7 = Perceptron_gradient(7)\n",
        "learning(a7,X_train,y_train)\n",
        "test_accuracy(a7,7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdg7jLhCgOuK",
        "outputId": "5c1f5199-a614-4288-e23e-dcfba2569e25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(98.11999999999999, 89.29961089494164)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a8 = Perceptron_gradient(8)\n",
        "learning(a8,X_train,y_train)\n",
        "test_accuracy(a8,8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yGSN-aSgVUF",
        "outputId": "7dbbca88-98a8-45d2-e33b-47e227f4ae32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(93.78, 47.43326488706365)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a9 = Perceptron_gradient(9)\n",
        "learning(a9,X_train,y_train)\n",
        "test_accuracy(a9,9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGrTTyLagb3z",
        "outputId": "9a826fb1-ffa1-48e3-b35a-cc40861642d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(93.72, 89.197224975223)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем общую точность: подаём картинку из тестовой выборки на вход каждого из 10 нейронов (каждый из них предварительно обучен распознавать одну цифру от 0 до 9) => считаем функцию активации (сигмоида) для каждого из десяти нейронов => смотрим, для какого из нейронов значение сигмоиды наибольшее (ближе всего к единице) => смотрим на цифру, которую распознает этот нейрон => если она свопадает с лейблом, то увеличиваем счетчик на 1. \n",
        "Делим значение счетчика на размер тествой выборки."
      ],
      "metadata": {
        "id": "OAAYCirdCnmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index_max_list = []\n",
        "counter = 0\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  list_of_val = []\n",
        "  X = np.insert(X_test[i].flatten(),0,1)\n",
        "  list_of_val.append(a0.sigmoida(X))\n",
        "  list_of_val.append(a1.sigmoida(X))\n",
        "  list_of_val.append(a2.sigmoida(X))\n",
        "  list_of_val.append(a3.sigmoida(X))\n",
        "  list_of_val.append(a4.sigmoida(X))\n",
        "  list_of_val.append(a5.sigmoida(X))\n",
        "  list_of_val.append(a6.sigmoida(X))\n",
        "  list_of_val.append(a7.sigmoida(X))\n",
        "  list_of_val.append(a8.sigmoida(X))\n",
        "  list_of_val.append(a9.sigmoida(X))\n",
        "  max_value = max(list_of_val)\n",
        "  index_max = list_of_val.index(max_value)\n",
        "  if index_max == y_test[i]:\n",
        "    counter += 1\n",
        "  index_max_list.append(index_max)"
      ],
      "metadata": {
        "id": "kyqx5fmMFitM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_common = counter / len(X_test) *100\n",
        "accuracy_common"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjyCcIOWJCsf",
        "outputId": "34067cf8-b40d-4242-dd74-1f4d63066228"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "85.06"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность \"однослойной неройнной сети\" равна 85.06%. То есть в 85.06 % процентах случаев данная \"однослойная нейронная сеть\" верно распознает число на картинке."
      ],
      "metadata": {
        "id": "8wGpxLWoErJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем полученные для первых 40 картинок тествой выборки (число 40 было взято произвольно) результаты в dataframe, для наглядности."
      ],
      "metadata": {
        "id": "GQ5JrDS1FWzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_list = []\n",
        "a0_list = []\n",
        "a1_list = []\n",
        "a2_list = []\n",
        "a3_list = []\n",
        "a4_list = []\n",
        "a5_list = []\n",
        "a6_list = []\n",
        "a7_list = []\n",
        "a8_list = []\n",
        "a9_list = []\n",
        "\n",
        "for i in range(40):\n",
        "  X = np.insert(X_test[i].flatten(),0,1)\n",
        "  a0_list.append(a0.sigmoida(X))\n",
        "  a1_list.append(a1.sigmoida(X))\n",
        "  a2_list.append(a2.sigmoida(X))\n",
        "  a3_list.append(a3.sigmoida(X))\n",
        "  a4_list.append(a4.sigmoida(X))\n",
        "  a5_list.append(a5.sigmoida(X))\n",
        "  a6_list.append(a6.sigmoida(X))\n",
        "  a7_list.append(a7.sigmoida(X))\n",
        "  a8_list.append(a8.sigmoida(X))\n",
        "  a9_list.append(a9.sigmoida(X))\n",
        "  y_test_list.append(y_test[i])"
      ],
      "metadata": {
        "id": "_5bh8uoX_q5c"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_name = ['Цифра 0','Цифра 1','Цифра 2','Цифра 3','Цифра 4','Цифра 5','Цифра 6','Цифра 7','Цифра 8','Цифра 9','Предсказанная цифра','Лейбл']\n",
        "df = pd.DataFrame(columns=columns_name)\n",
        "df['Цифра 0'] = a0_list\n",
        "df['Цифра 1'] = a1_list\n",
        "df['Цифра 2'] = a2_list\n",
        "df['Цифра 3'] = a3_list\n",
        "df['Цифра 4'] = a4_list\n",
        "df['Цифра 5'] = a5_list\n",
        "df['Цифра 6'] = a6_list\n",
        "df['Цифра 7'] = a7_list\n",
        "df['Цифра 8'] = a8_list\n",
        "df['Цифра 9'] = a9_list\n",
        "df['Предсказанная цифра'] = index_max_list[:40]\n",
        "df['Лейбл'] =   y_test_list\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "abwmdhvw-lUD",
        "outputId": "e1683c87-5d6e-4e61-c6a8-5db4dd30660a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Цифра 0   Цифра 1   Цифра 2   Цифра 3   Цифра 4   Цифра 5   Цифра 6  \\\n",
              "0   0.410686  0.309391  0.393504  0.434292  0.349769  0.396983  0.291114   \n",
              "1   0.406054  0.362775  0.479821  0.419692  0.219224  0.465992  0.461932   \n",
              "2   0.314152  0.546543  0.453675  0.436302  0.441089  0.453073  0.418975   \n",
              "3   0.565715  0.284672  0.335542  0.314230  0.257023  0.329037  0.407182   \n",
              "4   0.387447  0.375247  0.413430  0.332756  0.521792  0.356426  0.456313   \n",
              "5   0.285801  0.554801  0.418803  0.444054  0.441232  0.416051  0.376068   \n",
              "6   0.342624  0.357143  0.340605  0.397178  0.526450  0.441737  0.363473   \n",
              "7   0.244392  0.497838  0.402145  0.434871  0.428244  0.474052  0.398104   \n",
              "8   0.360004  0.382948  0.377677  0.204823  0.468871  0.446184  0.484345   \n",
              "9   0.326120  0.297887  0.294097  0.271954  0.415114  0.312191  0.333001   \n",
              "10  0.503528  0.323548  0.389895  0.381873  0.356563  0.383119  0.375618   \n",
              "11  0.334453  0.407692  0.376744  0.383123  0.391939  0.248075  0.491282   \n",
              "12  0.339393  0.324995  0.362188  0.380675  0.409579  0.403672  0.347443   \n",
              "13  0.523143  0.287334  0.385519  0.324078  0.361055  0.340116  0.363813   \n",
              "14  0.247580  0.553244  0.422066  0.501714  0.356585  0.394361  0.395564   \n",
              "15  0.375597  0.384461  0.317136  0.477667  0.376780  0.538276  0.358812   \n",
              "16  0.388700  0.306575  0.371949  0.340698  0.432194  0.337916  0.396473   \n",
              "17  0.420946  0.281904  0.383288  0.474724  0.334098  0.350804  0.286765   \n",
              "18  0.267768  0.340215  0.356650  0.449219  0.372188  0.464084  0.394822   \n",
              "19  0.371541  0.383371  0.389308  0.415345  0.534765  0.458343  0.406450   \n",
              "20  0.321567  0.344626  0.280444  0.426452  0.435169  0.358264  0.254111   \n",
              "21  0.340617  0.390589  0.372482  0.401976  0.359522  0.446261  0.531748   \n",
              "22  0.270996  0.412500  0.409070  0.330043  0.450523  0.258945  0.528357   \n",
              "23  0.364926  0.375929  0.373949  0.418376  0.455966  0.568501  0.414928   \n",
              "24  0.364552  0.431358  0.399341  0.430057  0.530719  0.453768  0.431539   \n",
              "25  0.577292  0.196104  0.291380  0.146886  0.311047  0.261651  0.404905   \n",
              "26  0.421434  0.390348  0.394128  0.406633  0.378069  0.455904  0.362985   \n",
              "27  0.351231  0.357365  0.392106  0.391738  0.532547  0.424362  0.418864   \n",
              "28  0.585292  0.257700  0.374915  0.386364  0.300565  0.349189  0.331620   \n",
              "29  0.274276  0.508616  0.432247  0.468523  0.391009  0.456993  0.450638   \n",
              "30  0.303505  0.376666  0.290497  0.607584  0.326307  0.437046  0.332811   \n",
              "31  0.286002  0.512899  0.428184  0.493011  0.421216  0.457492  0.426171   \n",
              "32  0.274547  0.352612  0.351182  0.573812  0.398621  0.465855  0.372833   \n",
              "33  0.415420  0.320379  0.425436  0.180930  0.416628  0.378474  0.485348   \n",
              "34  0.351209  0.341504  0.414710  0.401393  0.399809  0.375887  0.248365   \n",
              "35  0.418899  0.381576  0.546592  0.369661  0.297156  0.429356  0.345386   \n",
              "36  0.377564  0.329567  0.432468  0.425463  0.305994  0.413115  0.320557   \n",
              "37  0.247888  0.537687  0.429245  0.456061  0.395976  0.435020  0.425778   \n",
              "38  0.424805  0.443348  0.460861  0.523633  0.277516  0.435193  0.403503   \n",
              "39  0.273224  0.548400  0.391223  0.483249  0.376470  0.398269  0.415854   \n",
              "\n",
              "     Цифра 7   Цифра 8   Цифра 9  Предсказанная цифра  Лейбл  \n",
              "0   0.564380  0.374121  0.413519                    7      7  \n",
              "1   0.205375  0.367351  0.248405                    2      2  \n",
              "2   0.441060  0.413794  0.421334                    1      1  \n",
              "3   0.391240  0.347118  0.405655                    0      0  \n",
              "4   0.432913  0.351776  0.456202                    4      4  \n",
              "5   0.440861  0.420064  0.433463                    1      1  \n",
              "6   0.442646  0.435212  0.429042                    4      4  \n",
              "7   0.432016  0.395783  0.514208                    9      9  \n",
              "8   0.257369  0.319932  0.421811                    6      5  \n",
              "9   0.484000  0.453561  0.568965                    9      9  \n",
              "10  0.339586  0.403258  0.301713                    0      0  \n",
              "11  0.324024  0.419133  0.337259                    6      6  \n",
              "12  0.456735  0.385730  0.572537                    9      9  \n",
              "13  0.424024  0.434785  0.421584                    0      0  \n",
              "14  0.391374  0.433924  0.464719                    1      1  \n",
              "15  0.399999  0.424041  0.281712                    5      5  \n",
              "16  0.463558  0.350422  0.534304                    9      9  \n",
              "17  0.566496  0.326005  0.363745                    7      7  \n",
              "18  0.336529  0.324528  0.249334                    5      3  \n",
              "19  0.424309  0.375408  0.495475                    4      4  \n",
              "20  0.480557  0.422921  0.549244                    9      9  \n",
              "21  0.309358  0.371763  0.413022                    6      6  \n",
              "22  0.443077  0.367550  0.405251                    6      6  \n",
              "23  0.305134  0.432488  0.412220                    5      5  \n",
              "24  0.482311  0.320836  0.467990                    4      4  \n",
              "25  0.302615  0.345265  0.280438                    0      0  \n",
              "26  0.564795  0.333600  0.472573                    7      7  \n",
              "27  0.393987  0.353085  0.512872                    4      4  \n",
              "28  0.357752  0.380960  0.399225                    0      0  \n",
              "29  0.400585  0.452170  0.459422                    1      1  \n",
              "30  0.433079  0.371127  0.440675                    3      3  \n",
              "31  0.458113  0.408777  0.480692                    1      1  \n",
              "32  0.344094  0.354055  0.401225                    3      3  \n",
              "33  0.376548  0.392523  0.349770                    6      4  \n",
              "34  0.525304  0.389044  0.442282                    7      7  \n",
              "35  0.298280  0.393341  0.222888                    2      2  \n",
              "36  0.548563  0.347020  0.438211                    7      7  \n",
              "37  0.431081  0.446604  0.477962                    1      1  \n",
              "38  0.310637  0.421694  0.368779                    3      2  \n",
              "39  0.373123  0.473359  0.475622                    1      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08e602fd-faeb-455e-85f5-524a349efb19\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Цифра 0</th>\n",
              "      <th>Цифра 1</th>\n",
              "      <th>Цифра 2</th>\n",
              "      <th>Цифра 3</th>\n",
              "      <th>Цифра 4</th>\n",
              "      <th>Цифра 5</th>\n",
              "      <th>Цифра 6</th>\n",
              "      <th>Цифра 7</th>\n",
              "      <th>Цифра 8</th>\n",
              "      <th>Цифра 9</th>\n",
              "      <th>Предсказанная цифра</th>\n",
              "      <th>Лейбл</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.410686</td>\n",
              "      <td>0.309391</td>\n",
              "      <td>0.393504</td>\n",
              "      <td>0.434292</td>\n",
              "      <td>0.349769</td>\n",
              "      <td>0.396983</td>\n",
              "      <td>0.291114</td>\n",
              "      <td>0.564380</td>\n",
              "      <td>0.374121</td>\n",
              "      <td>0.413519</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.406054</td>\n",
              "      <td>0.362775</td>\n",
              "      <td>0.479821</td>\n",
              "      <td>0.419692</td>\n",
              "      <td>0.219224</td>\n",
              "      <td>0.465992</td>\n",
              "      <td>0.461932</td>\n",
              "      <td>0.205375</td>\n",
              "      <td>0.367351</td>\n",
              "      <td>0.248405</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.314152</td>\n",
              "      <td>0.546543</td>\n",
              "      <td>0.453675</td>\n",
              "      <td>0.436302</td>\n",
              "      <td>0.441089</td>\n",
              "      <td>0.453073</td>\n",
              "      <td>0.418975</td>\n",
              "      <td>0.441060</td>\n",
              "      <td>0.413794</td>\n",
              "      <td>0.421334</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.565715</td>\n",
              "      <td>0.284672</td>\n",
              "      <td>0.335542</td>\n",
              "      <td>0.314230</td>\n",
              "      <td>0.257023</td>\n",
              "      <td>0.329037</td>\n",
              "      <td>0.407182</td>\n",
              "      <td>0.391240</td>\n",
              "      <td>0.347118</td>\n",
              "      <td>0.405655</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.387447</td>\n",
              "      <td>0.375247</td>\n",
              "      <td>0.413430</td>\n",
              "      <td>0.332756</td>\n",
              "      <td>0.521792</td>\n",
              "      <td>0.356426</td>\n",
              "      <td>0.456313</td>\n",
              "      <td>0.432913</td>\n",
              "      <td>0.351776</td>\n",
              "      <td>0.456202</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.285801</td>\n",
              "      <td>0.554801</td>\n",
              "      <td>0.418803</td>\n",
              "      <td>0.444054</td>\n",
              "      <td>0.441232</td>\n",
              "      <td>0.416051</td>\n",
              "      <td>0.376068</td>\n",
              "      <td>0.440861</td>\n",
              "      <td>0.420064</td>\n",
              "      <td>0.433463</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.342624</td>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.340605</td>\n",
              "      <td>0.397178</td>\n",
              "      <td>0.526450</td>\n",
              "      <td>0.441737</td>\n",
              "      <td>0.363473</td>\n",
              "      <td>0.442646</td>\n",
              "      <td>0.435212</td>\n",
              "      <td>0.429042</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.244392</td>\n",
              "      <td>0.497838</td>\n",
              "      <td>0.402145</td>\n",
              "      <td>0.434871</td>\n",
              "      <td>0.428244</td>\n",
              "      <td>0.474052</td>\n",
              "      <td>0.398104</td>\n",
              "      <td>0.432016</td>\n",
              "      <td>0.395783</td>\n",
              "      <td>0.514208</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.360004</td>\n",
              "      <td>0.382948</td>\n",
              "      <td>0.377677</td>\n",
              "      <td>0.204823</td>\n",
              "      <td>0.468871</td>\n",
              "      <td>0.446184</td>\n",
              "      <td>0.484345</td>\n",
              "      <td>0.257369</td>\n",
              "      <td>0.319932</td>\n",
              "      <td>0.421811</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.326120</td>\n",
              "      <td>0.297887</td>\n",
              "      <td>0.294097</td>\n",
              "      <td>0.271954</td>\n",
              "      <td>0.415114</td>\n",
              "      <td>0.312191</td>\n",
              "      <td>0.333001</td>\n",
              "      <td>0.484000</td>\n",
              "      <td>0.453561</td>\n",
              "      <td>0.568965</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.503528</td>\n",
              "      <td>0.323548</td>\n",
              "      <td>0.389895</td>\n",
              "      <td>0.381873</td>\n",
              "      <td>0.356563</td>\n",
              "      <td>0.383119</td>\n",
              "      <td>0.375618</td>\n",
              "      <td>0.339586</td>\n",
              "      <td>0.403258</td>\n",
              "      <td>0.301713</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.334453</td>\n",
              "      <td>0.407692</td>\n",
              "      <td>0.376744</td>\n",
              "      <td>0.383123</td>\n",
              "      <td>0.391939</td>\n",
              "      <td>0.248075</td>\n",
              "      <td>0.491282</td>\n",
              "      <td>0.324024</td>\n",
              "      <td>0.419133</td>\n",
              "      <td>0.337259</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.339393</td>\n",
              "      <td>0.324995</td>\n",
              "      <td>0.362188</td>\n",
              "      <td>0.380675</td>\n",
              "      <td>0.409579</td>\n",
              "      <td>0.403672</td>\n",
              "      <td>0.347443</td>\n",
              "      <td>0.456735</td>\n",
              "      <td>0.385730</td>\n",
              "      <td>0.572537</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.523143</td>\n",
              "      <td>0.287334</td>\n",
              "      <td>0.385519</td>\n",
              "      <td>0.324078</td>\n",
              "      <td>0.361055</td>\n",
              "      <td>0.340116</td>\n",
              "      <td>0.363813</td>\n",
              "      <td>0.424024</td>\n",
              "      <td>0.434785</td>\n",
              "      <td>0.421584</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.247580</td>\n",
              "      <td>0.553244</td>\n",
              "      <td>0.422066</td>\n",
              "      <td>0.501714</td>\n",
              "      <td>0.356585</td>\n",
              "      <td>0.394361</td>\n",
              "      <td>0.395564</td>\n",
              "      <td>0.391374</td>\n",
              "      <td>0.433924</td>\n",
              "      <td>0.464719</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.375597</td>\n",
              "      <td>0.384461</td>\n",
              "      <td>0.317136</td>\n",
              "      <td>0.477667</td>\n",
              "      <td>0.376780</td>\n",
              "      <td>0.538276</td>\n",
              "      <td>0.358812</td>\n",
              "      <td>0.399999</td>\n",
              "      <td>0.424041</td>\n",
              "      <td>0.281712</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.388700</td>\n",
              "      <td>0.306575</td>\n",
              "      <td>0.371949</td>\n",
              "      <td>0.340698</td>\n",
              "      <td>0.432194</td>\n",
              "      <td>0.337916</td>\n",
              "      <td>0.396473</td>\n",
              "      <td>0.463558</td>\n",
              "      <td>0.350422</td>\n",
              "      <td>0.534304</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.420946</td>\n",
              "      <td>0.281904</td>\n",
              "      <td>0.383288</td>\n",
              "      <td>0.474724</td>\n",
              "      <td>0.334098</td>\n",
              "      <td>0.350804</td>\n",
              "      <td>0.286765</td>\n",
              "      <td>0.566496</td>\n",
              "      <td>0.326005</td>\n",
              "      <td>0.363745</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.267768</td>\n",
              "      <td>0.340215</td>\n",
              "      <td>0.356650</td>\n",
              "      <td>0.449219</td>\n",
              "      <td>0.372188</td>\n",
              "      <td>0.464084</td>\n",
              "      <td>0.394822</td>\n",
              "      <td>0.336529</td>\n",
              "      <td>0.324528</td>\n",
              "      <td>0.249334</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.371541</td>\n",
              "      <td>0.383371</td>\n",
              "      <td>0.389308</td>\n",
              "      <td>0.415345</td>\n",
              "      <td>0.534765</td>\n",
              "      <td>0.458343</td>\n",
              "      <td>0.406450</td>\n",
              "      <td>0.424309</td>\n",
              "      <td>0.375408</td>\n",
              "      <td>0.495475</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.321567</td>\n",
              "      <td>0.344626</td>\n",
              "      <td>0.280444</td>\n",
              "      <td>0.426452</td>\n",
              "      <td>0.435169</td>\n",
              "      <td>0.358264</td>\n",
              "      <td>0.254111</td>\n",
              "      <td>0.480557</td>\n",
              "      <td>0.422921</td>\n",
              "      <td>0.549244</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.340617</td>\n",
              "      <td>0.390589</td>\n",
              "      <td>0.372482</td>\n",
              "      <td>0.401976</td>\n",
              "      <td>0.359522</td>\n",
              "      <td>0.446261</td>\n",
              "      <td>0.531748</td>\n",
              "      <td>0.309358</td>\n",
              "      <td>0.371763</td>\n",
              "      <td>0.413022</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.270996</td>\n",
              "      <td>0.412500</td>\n",
              "      <td>0.409070</td>\n",
              "      <td>0.330043</td>\n",
              "      <td>0.450523</td>\n",
              "      <td>0.258945</td>\n",
              "      <td>0.528357</td>\n",
              "      <td>0.443077</td>\n",
              "      <td>0.367550</td>\n",
              "      <td>0.405251</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.364926</td>\n",
              "      <td>0.375929</td>\n",
              "      <td>0.373949</td>\n",
              "      <td>0.418376</td>\n",
              "      <td>0.455966</td>\n",
              "      <td>0.568501</td>\n",
              "      <td>0.414928</td>\n",
              "      <td>0.305134</td>\n",
              "      <td>0.432488</td>\n",
              "      <td>0.412220</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.364552</td>\n",
              "      <td>0.431358</td>\n",
              "      <td>0.399341</td>\n",
              "      <td>0.430057</td>\n",
              "      <td>0.530719</td>\n",
              "      <td>0.453768</td>\n",
              "      <td>0.431539</td>\n",
              "      <td>0.482311</td>\n",
              "      <td>0.320836</td>\n",
              "      <td>0.467990</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.577292</td>\n",
              "      <td>0.196104</td>\n",
              "      <td>0.291380</td>\n",
              "      <td>0.146886</td>\n",
              "      <td>0.311047</td>\n",
              "      <td>0.261651</td>\n",
              "      <td>0.404905</td>\n",
              "      <td>0.302615</td>\n",
              "      <td>0.345265</td>\n",
              "      <td>0.280438</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.421434</td>\n",
              "      <td>0.390348</td>\n",
              "      <td>0.394128</td>\n",
              "      <td>0.406633</td>\n",
              "      <td>0.378069</td>\n",
              "      <td>0.455904</td>\n",
              "      <td>0.362985</td>\n",
              "      <td>0.564795</td>\n",
              "      <td>0.333600</td>\n",
              "      <td>0.472573</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0.351231</td>\n",
              "      <td>0.357365</td>\n",
              "      <td>0.392106</td>\n",
              "      <td>0.391738</td>\n",
              "      <td>0.532547</td>\n",
              "      <td>0.424362</td>\n",
              "      <td>0.418864</td>\n",
              "      <td>0.393987</td>\n",
              "      <td>0.353085</td>\n",
              "      <td>0.512872</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.585292</td>\n",
              "      <td>0.257700</td>\n",
              "      <td>0.374915</td>\n",
              "      <td>0.386364</td>\n",
              "      <td>0.300565</td>\n",
              "      <td>0.349189</td>\n",
              "      <td>0.331620</td>\n",
              "      <td>0.357752</td>\n",
              "      <td>0.380960</td>\n",
              "      <td>0.399225</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0.274276</td>\n",
              "      <td>0.508616</td>\n",
              "      <td>0.432247</td>\n",
              "      <td>0.468523</td>\n",
              "      <td>0.391009</td>\n",
              "      <td>0.456993</td>\n",
              "      <td>0.450638</td>\n",
              "      <td>0.400585</td>\n",
              "      <td>0.452170</td>\n",
              "      <td>0.459422</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>0.303505</td>\n",
              "      <td>0.376666</td>\n",
              "      <td>0.290497</td>\n",
              "      <td>0.607584</td>\n",
              "      <td>0.326307</td>\n",
              "      <td>0.437046</td>\n",
              "      <td>0.332811</td>\n",
              "      <td>0.433079</td>\n",
              "      <td>0.371127</td>\n",
              "      <td>0.440675</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>0.286002</td>\n",
              "      <td>0.512899</td>\n",
              "      <td>0.428184</td>\n",
              "      <td>0.493011</td>\n",
              "      <td>0.421216</td>\n",
              "      <td>0.457492</td>\n",
              "      <td>0.426171</td>\n",
              "      <td>0.458113</td>\n",
              "      <td>0.408777</td>\n",
              "      <td>0.480692</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>0.274547</td>\n",
              "      <td>0.352612</td>\n",
              "      <td>0.351182</td>\n",
              "      <td>0.573812</td>\n",
              "      <td>0.398621</td>\n",
              "      <td>0.465855</td>\n",
              "      <td>0.372833</td>\n",
              "      <td>0.344094</td>\n",
              "      <td>0.354055</td>\n",
              "      <td>0.401225</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>0.415420</td>\n",
              "      <td>0.320379</td>\n",
              "      <td>0.425436</td>\n",
              "      <td>0.180930</td>\n",
              "      <td>0.416628</td>\n",
              "      <td>0.378474</td>\n",
              "      <td>0.485348</td>\n",
              "      <td>0.376548</td>\n",
              "      <td>0.392523</td>\n",
              "      <td>0.349770</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.351209</td>\n",
              "      <td>0.341504</td>\n",
              "      <td>0.414710</td>\n",
              "      <td>0.401393</td>\n",
              "      <td>0.399809</td>\n",
              "      <td>0.375887</td>\n",
              "      <td>0.248365</td>\n",
              "      <td>0.525304</td>\n",
              "      <td>0.389044</td>\n",
              "      <td>0.442282</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>0.418899</td>\n",
              "      <td>0.381576</td>\n",
              "      <td>0.546592</td>\n",
              "      <td>0.369661</td>\n",
              "      <td>0.297156</td>\n",
              "      <td>0.429356</td>\n",
              "      <td>0.345386</td>\n",
              "      <td>0.298280</td>\n",
              "      <td>0.393341</td>\n",
              "      <td>0.222888</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>0.377564</td>\n",
              "      <td>0.329567</td>\n",
              "      <td>0.432468</td>\n",
              "      <td>0.425463</td>\n",
              "      <td>0.305994</td>\n",
              "      <td>0.413115</td>\n",
              "      <td>0.320557</td>\n",
              "      <td>0.548563</td>\n",
              "      <td>0.347020</td>\n",
              "      <td>0.438211</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.247888</td>\n",
              "      <td>0.537687</td>\n",
              "      <td>0.429245</td>\n",
              "      <td>0.456061</td>\n",
              "      <td>0.395976</td>\n",
              "      <td>0.435020</td>\n",
              "      <td>0.425778</td>\n",
              "      <td>0.431081</td>\n",
              "      <td>0.446604</td>\n",
              "      <td>0.477962</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.424805</td>\n",
              "      <td>0.443348</td>\n",
              "      <td>0.460861</td>\n",
              "      <td>0.523633</td>\n",
              "      <td>0.277516</td>\n",
              "      <td>0.435193</td>\n",
              "      <td>0.403503</td>\n",
              "      <td>0.310637</td>\n",
              "      <td>0.421694</td>\n",
              "      <td>0.368779</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0.273224</td>\n",
              "      <td>0.548400</td>\n",
              "      <td>0.391223</td>\n",
              "      <td>0.483249</td>\n",
              "      <td>0.376470</td>\n",
              "      <td>0.398269</td>\n",
              "      <td>0.415854</td>\n",
              "      <td>0.373123</td>\n",
              "      <td>0.473359</td>\n",
              "      <td>0.475622</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08e602fd-faeb-455e-85f5-524a349efb19')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08e602fd-faeb-455e-85f5-524a349efb19 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08e602fd-faeb-455e-85f5-524a349efb19');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}